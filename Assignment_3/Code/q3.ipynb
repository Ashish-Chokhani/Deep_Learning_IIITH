{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z', '7', '!', '&', 'k', 'o', 'g', 'w', '.', 'I', 'm', '6', '0', 'E', 'H', '[', '}', 'C', 'P', ':', '\\\\', 'D', '@', 'R', 'W', 'e', 'F', 'J', 'j', '#', '4', 'Q', 'd', 'r', ')', 's', '8', '/', 'b', 'f', 'i', '3', '5', 'Z', 'c', '{', '^', 'U', '$', ']', ' ', 'A', 'y', 'V', \"'\", 'l', 'x', '\"', 'n', 'a', 'L', '?', '(', 'G', 'S', '-', '9', '2', 'p', '*', '1', ',', 'T', 'B', 't', 'Y', 'q', 'v', 'O', 'h', 'u', 'M', 'X', 'K', '+', 'N'}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "\n",
    "embedding_dim = 512\n",
    "hidden_dim = 512\n",
    "dropout_prob = 0.5\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "num_steps = 20000 \n",
    "max_source_seq_length = 500\n",
    "\n",
    "train_sources_path = \"train.sources\"\n",
    "train_targets_path = \"train.targets\"\n",
    "dev_sources_path = \"dev.sources\"\n",
    "dev_targets_path = \"dev.targets\"\n",
    "test_sources_path = \"test.sources\"\n",
    "test_targets_path = \"test.targets\"\n",
    "\n",
    "padding_token = '^'\n",
    "\n",
    "def update_vocab(text, vocab, char_to_index):\n",
    "    for char in text:\n",
    "        if char not in vocab:\n",
    "            index = len(vocab)\n",
    "            vocab.add(char)\n",
    "            char_to_index[char] = index\n",
    "\n",
    "# Load and preprocess the source and target data with padding\n",
    "def load_and_preprocess_data(source_path, target_path, char_to_index, max_seq_length):\n",
    "    source_data = []\n",
    "    target_data = []\n",
    "\n",
    "    with open(source_path, \"r\") as source_file, open(target_path, \"r\") as target_file:\n",
    "        source_lines = source_file.readlines()\n",
    "        target_lines = target_file.readlines()\n",
    "\n",
    "        for source_line, target_line in zip(source_lines, target_lines):\n",
    "            source_line = f'#{source_line.strip()[:max_seq_length]}@'\n",
    "            target_line = f'#{target_line.strip()[:max_seq_length]}@'\n",
    "\n",
    "            source_data.append(source_line)\n",
    "            target_data.append(target_line)\n",
    "\n",
    "    # Pad sequences with the padding token\n",
    "    source_data = [source.ljust(max_seq_length, padding_token) for source in source_data]\n",
    "    target_data = [target.ljust(max_seq_length, padding_token) for target in target_data]\n",
    "\n",
    "    update_vocab(''.join(source_data), char_vocab, char_to_index)\n",
    "    update_vocab(''.join(target_data), char_vocab, char_to_index)\n",
    "\n",
    "    source_data = [[char_to_index[char] for char in source] for source in source_data]\n",
    "    target_data = [[char_to_index[char] for char in target] for target in target_data]\n",
    "\n",
    "    return source_data, target_data\n",
    "\n",
    "# Create character vocabularies and index dictionaries\n",
    "char_vocab = set()\n",
    "char_to_index = {}\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_source_data, train_target_data = load_and_preprocess_data(\n",
    "    train_sources_path, train_targets_path, char_to_index, max_source_seq_length\n",
    ")\n",
    "\n",
    "val_source_data, val_target_data = load_and_preprocess_data(\n",
    "    dev_sources_path, dev_targets_path, char_to_index, max_source_seq_length\n",
    ")\n",
    "\n",
    "test_source_data, test_target_data = load_and_preprocess_data(\n",
    "    test_sources_path, test_targets_path, char_to_index, max_source_seq_length\n",
    ")\n",
    "\n",
    "# num_epochs = num_steps // (len(train_source_data) // batch_size) + 1\n",
    "num_epochs=200\n",
    "\n",
    "# Define your custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, source_data, target_data):\n",
    "        self.source_data = source_data\n",
    "        self.target_data = target_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.source_data[idx], dtype=torch.long), torch.tensor(self.target_data[idx], dtype=torch.long)\n",
    "    \n",
    "train_source_data = torch.tensor(train_source_data, dtype=torch.long)\n",
    "train_target_data = torch.tensor(train_target_data, dtype=torch.long)\n",
    "\n",
    "val_source_data = torch.tensor(val_source_data, dtype=torch.long)\n",
    "val_target_data = torch.tensor(val_target_data, dtype=torch.long)\n",
    "\n",
    "test_source_data = torch.tensor(test_source_data, dtype=torch.long)\n",
    "test_target_data = torch.tensor(test_target_data, dtype=torch.long)\n",
    "\n",
    "print(char_vocab)\n",
    "print(char_to_index['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.repeat(seq_len, 1, 1).transpose(0, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden.permute(1,0,2), encoder_outputs), dim=2)))\n",
    "        attention_scores = torch.matmul(energy, self.v)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=0)\n",
    "        context_vector = torch.sum(attention_weights.unsqueeze(2) * encoder_outputs, dim=0)\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim + hidden_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        context_vector = self.attention(hidden[-1], encoder_outputs)\n",
    "        emb_con = torch.cat((embedded, context_vector.unsqueeze(0)), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(emb_con, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            input = (trg[t] if teacher_force else top1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "INPUT_DIM = len(char_vocab)\n",
    "OUTPUT_DIM = len(char_vocab)\n",
    "N_LAYERS = 2\n",
    "ENC_EMB_DIM = embedding_dim\n",
    "DEC_EMB_DIM = embedding_dim\n",
    "HID_DIM = hidden_dim\n",
    "ENC_DROPOUT = dropout_prob\n",
    "DEC_DROPOUT = dropout_prob\n",
    "\n",
    "attention = Attention(HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attention).to(device)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "ignore_index = char_to_index[padding_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model on the validation set\n",
    "def evaluate(model,step,source_data,target_data, criterion,device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        start_idx = step * batch_size\n",
    "        end_idx = (step + 1) * batch_size\n",
    "        source_batch = source_data[start_idx:end_idx].to(device)\n",
    "        target_batch = target_data[start_idx:end_idx].to(device)\n",
    "        \n",
    "        source_batch, target_batch = source_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        output = model(source_batch, target_batch, teacher_forcing_ratio=0.0)  # Set teacher_forcing_ratio to 0 during evaluation\n",
    "        output_dim = output.shape[2]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        target_batch = target_batch[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, target_batch)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,step,source_data,target_data,criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    start_idx = step * batch_size\n",
    "    end_idx = (step + 1) * batch_size\n",
    "    source_batch = source_data[start_idx:end_idx].to(device)\n",
    "    target_batch = target_data[start_idx:end_idx].to(device)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(source_batch, target_batch)\n",
    "\n",
    "    # Reshape output and target for calculating the loss\n",
    "    output_dim = output.shape[2]\n",
    "    output = output[1:].view(-1, output_dim)\n",
    "    target_batch = target_batch[1:].view(-1)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, target_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]: Training Loss: 4.4523\n",
      "Epoch [1/200]: Validation Loss: 4.4414\n",
      "Epoch [2/200]: Training Loss: 4.4409\n",
      "Epoch [2/200]: Validation Loss: 4.4246\n",
      "Epoch [3/200]: Training Loss: 4.4299\n",
      "Epoch [3/200]: Validation Loss: 4.4002\n",
      "Epoch [4/200]: Training Loss: 4.4169\n",
      "Epoch [4/200]: Validation Loss: 4.3682\n",
      "Epoch [5/200]: Training Loss: 4.3960\n",
      "Epoch [5/200]: Validation Loss: 4.3435\n",
      "Epoch [6/200]: Training Loss: 4.3837\n",
      "Epoch [6/200]: Validation Loss: 4.3213\n",
      "Epoch [7/200]: Training Loss: 4.3494\n",
      "Epoch [7/200]: Validation Loss: 4.2801\n",
      "Epoch [8/200]: Training Loss: 4.3344\n",
      "Epoch [8/200]: Validation Loss: 4.2318\n",
      "Epoch [9/200]: Training Loss: 4.2998\n",
      "Epoch [9/200]: Validation Loss: 4.1995\n",
      "Epoch [10/200]: Training Loss: 4.2619\n",
      "Epoch [10/200]: Validation Loss: 4.1473\n",
      "Epoch [11/200]: Training Loss: 4.2331\n",
      "Epoch [11/200]: Validation Loss: 4.0566\n",
      "Epoch [12/200]: Training Loss: 4.1759\n",
      "Epoch [12/200]: Validation Loss: 3.9780\n",
      "Epoch [13/200]: Training Loss: 4.1103\n",
      "Epoch [13/200]: Validation Loss: 3.9165\n",
      "Epoch [14/200]: Training Loss: 4.0822\n",
      "Epoch [14/200]: Validation Loss: 3.8485\n",
      "Epoch [15/200]: Training Loss: 3.9877\n",
      "Epoch [15/200]: Validation Loss: 3.7559\n",
      "Epoch [16/200]: Training Loss: 3.9307\n",
      "Epoch [16/200]: Validation Loss: 3.7108\n",
      "Epoch [17/200]: Training Loss: 3.8062\n",
      "Epoch [17/200]: Validation Loss: 3.6780\n",
      "Epoch [18/200]: Training Loss: 3.7612\n",
      "Epoch [18/200]: Validation Loss: 3.6658\n",
      "Epoch [19/200]: Training Loss: 3.6652\n",
      "Epoch [19/200]: Validation Loss: 3.6748\n",
      "Epoch [20/200]: Training Loss: 3.6221\n",
      "Epoch [20/200]: Validation Loss: 3.6607\n",
      "Epoch [21/200]: Training Loss: 3.5664\n",
      "Epoch [21/200]: Validation Loss: 3.6160\n",
      "Epoch [22/200]: Training Loss: 3.5039\n",
      "Epoch [22/200]: Validation Loss: 3.5616\n",
      "Epoch [23/200]: Training Loss: 3.4513\n",
      "Epoch [23/200]: Validation Loss: 3.5066\n",
      "Epoch [24/200]: Training Loss: 3.4268\n",
      "Epoch [24/200]: Validation Loss: 3.4307\n",
      "Epoch [25/200]: Training Loss: 3.3851\n",
      "Epoch [25/200]: Validation Loss: 3.3610\n",
      "Epoch [26/200]: Training Loss: 3.3219\n",
      "Epoch [26/200]: Validation Loss: 3.2967\n",
      "Epoch [27/200]: Training Loss: 3.2827\n",
      "Epoch [27/200]: Validation Loss: 3.2596\n",
      "Epoch [28/200]: Training Loss: 3.2325\n",
      "Epoch [28/200]: Validation Loss: 3.2204\n",
      "Epoch [29/200]: Training Loss: 3.2207\n",
      "Epoch [29/200]: Validation Loss: 3.1915\n",
      "Epoch [30/200]: Training Loss: 3.1953\n",
      "Epoch [30/200]: Validation Loss: 3.1711\n",
      "Epoch [31/200]: Training Loss: 3.1845\n",
      "Epoch [31/200]: Validation Loss: 3.1563\n",
      "Epoch [32/200]: Training Loss: 3.1695\n",
      "Epoch [32/200]: Validation Loss: 3.1464\n",
      "Epoch [33/200]: Training Loss: 3.1513\n",
      "Epoch [33/200]: Validation Loss: 3.1326\n",
      "Epoch [34/200]: Training Loss: 3.1384\n",
      "Epoch [34/200]: Validation Loss: 3.1245\n",
      "Epoch [35/200]: Training Loss: 3.1147\n",
      "Epoch [35/200]: Validation Loss: 3.1123\n",
      "Epoch [36/200]: Training Loss: 3.1054\n",
      "Epoch [36/200]: Validation Loss: 3.1057\n",
      "Epoch [37/200]: Training Loss: 3.0930\n",
      "Epoch [37/200]: Validation Loss: 3.0939\n",
      "Epoch [38/200]: Training Loss: 3.0790\n",
      "Epoch [38/200]: Validation Loss: 3.0804\n",
      "Epoch [39/200]: Training Loss: 3.0777\n",
      "Epoch [39/200]: Validation Loss: 3.0851\n",
      "Epoch [40/200]: Training Loss: 3.0637\n",
      "Epoch [40/200]: Validation Loss: 3.0812\n",
      "Epoch [41/200]: Training Loss: 3.0628\n",
      "Epoch [41/200]: Validation Loss: 3.0765\n",
      "Epoch [42/200]: Training Loss: 3.0536\n",
      "Epoch [42/200]: Validation Loss: 3.0760\n",
      "Epoch [43/200]: Training Loss: 3.0522\n",
      "Epoch [43/200]: Validation Loss: 3.0570\n",
      "Epoch [44/200]: Training Loss: 3.0490\n",
      "Epoch [44/200]: Validation Loss: 3.0552\n",
      "Epoch [45/200]: Training Loss: 3.0387\n",
      "Epoch [45/200]: Validation Loss: 3.0421\n",
      "Epoch [46/200]: Training Loss: 3.0279\n",
      "Epoch [46/200]: Validation Loss: 3.0476\n",
      "Epoch [47/200]: Training Loss: 3.0214\n",
      "Epoch [47/200]: Validation Loss: 3.0443\n",
      "Epoch [48/200]: Training Loss: 3.0247\n",
      "Epoch [48/200]: Validation Loss: 3.0421\n",
      "Epoch [49/200]: Training Loss: 3.0194\n",
      "Epoch [49/200]: Validation Loss: 3.0429\n",
      "Epoch [50/200]: Training Loss: 3.0096\n",
      "Epoch [50/200]: Validation Loss: 3.0406\n",
      "Epoch [51/200]: Training Loss: 3.0001\n",
      "Epoch [51/200]: Validation Loss: 3.0422\n",
      "Epoch [52/200]: Training Loss: 3.0184\n",
      "Epoch [52/200]: Validation Loss: 3.0349\n",
      "Epoch [53/200]: Training Loss: 2.9959\n",
      "Epoch [53/200]: Validation Loss: 3.0415\n",
      "Epoch [54/200]: Training Loss: 2.9834\n",
      "Epoch [54/200]: Validation Loss: 3.0421\n",
      "Epoch [55/200]: Training Loss: 2.9795\n",
      "Epoch [55/200]: Validation Loss: 3.0466\n",
      "Epoch [56/200]: Training Loss: 2.9859\n",
      "Epoch [56/200]: Validation Loss: 3.0416\n",
      "Epoch [57/200]: Training Loss: 2.9821\n",
      "Epoch [57/200]: Validation Loss: 3.0494\n",
      "Epoch [58/200]: Training Loss: 2.9620\n",
      "Epoch [58/200]: Validation Loss: 3.0444\n",
      "Epoch [59/200]: Training Loss: 2.9508\n",
      "Epoch [59/200]: Validation Loss: 3.0423\n",
      "Epoch [60/200]: Training Loss: 2.9536\n",
      "Epoch [60/200]: Validation Loss: 3.0622\n",
      "Epoch [61/200]: Training Loss: 2.9660\n",
      "Epoch [61/200]: Validation Loss: 3.0509\n",
      "Epoch [62/200]: Training Loss: 2.9433\n",
      "Epoch [62/200]: Validation Loss: 3.0512\n",
      "Epoch [63/200]: Training Loss: 2.9345\n",
      "Epoch [63/200]: Validation Loss: 3.0572\n",
      "Epoch [64/200]: Training Loss: 2.9325\n",
      "Epoch [64/200]: Validation Loss: 3.0526\n",
      "Epoch [65/200]: Training Loss: 2.9172\n",
      "Epoch [65/200]: Validation Loss: 3.0759\n",
      "Epoch [66/200]: Training Loss: 2.9350\n",
      "Epoch [66/200]: Validation Loss: 3.0789\n",
      "Epoch [67/200]: Training Loss: 2.8533\n",
      "Epoch [67/200]: Validation Loss: 3.1061\n",
      "Epoch [68/200]: Training Loss: 2.8694\n",
      "Epoch [68/200]: Validation Loss: 3.1225\n",
      "Epoch [69/200]: Training Loss: 2.8859\n",
      "Epoch [69/200]: Validation Loss: 3.1413\n",
      "Epoch [70/200]: Training Loss: 2.9062\n",
      "Epoch [70/200]: Validation Loss: 3.1374\n",
      "Epoch [71/200]: Training Loss: 2.8595\n",
      "Epoch [71/200]: Validation Loss: 3.1283\n",
      "Epoch [72/200]: Training Loss: 2.8771\n",
      "Epoch [72/200]: Validation Loss: 3.1100\n",
      "Epoch [73/200]: Training Loss: 2.8412\n",
      "Epoch [73/200]: Validation Loss: 3.1112\n",
      "Epoch [74/200]: Training Loss: 2.8682\n",
      "Epoch [74/200]: Validation Loss: 3.1237\n",
      "Epoch [75/200]: Training Loss: 2.8145\n",
      "Epoch [75/200]: Validation Loss: 3.1333\n",
      "Epoch [76/200]: Training Loss: 2.8357\n",
      "Epoch [76/200]: Validation Loss: 3.1740\n",
      "Epoch [77/200]: Training Loss: 2.7959\n",
      "Epoch [77/200]: Validation Loss: 3.1890\n",
      "Epoch [78/200]: Training Loss: 2.7549\n",
      "Epoch [78/200]: Validation Loss: 3.2110\n",
      "Epoch [79/200]: Training Loss: 2.9286\n",
      "Epoch [79/200]: Validation Loss: 3.1820\n",
      "Epoch [80/200]: Training Loss: 2.8176\n",
      "Epoch [80/200]: Validation Loss: 3.1063\n",
      "Epoch [81/200]: Training Loss: 2.7664\n",
      "Epoch [81/200]: Validation Loss: 3.0420\n",
      "Epoch [82/200]: Training Loss: 2.7944\n",
      "Epoch [82/200]: Validation Loss: 3.0864\n",
      "Epoch [83/200]: Training Loss: 2.8163\n",
      "Epoch [83/200]: Validation Loss: 3.1325\n",
      "Epoch [84/200]: Training Loss: 2.6999\n",
      "Epoch [84/200]: Validation Loss: 3.2062\n",
      "Epoch [85/200]: Training Loss: 2.7427\n",
      "Epoch [85/200]: Validation Loss: 3.2258\n",
      "Epoch [86/200]: Training Loss: 2.7533\n",
      "Epoch [86/200]: Validation Loss: 3.2567\n",
      "Epoch [87/200]: Training Loss: 2.6875\n",
      "Epoch [87/200]: Validation Loss: 3.2554\n",
      "Epoch [88/200]: Training Loss: 2.7376\n",
      "Epoch [88/200]: Validation Loss: 3.2512\n",
      "Epoch [89/200]: Training Loss: 2.7961\n",
      "Epoch [89/200]: Validation Loss: 3.1640\n",
      "Epoch [90/200]: Training Loss: 2.8121\n",
      "Epoch [90/200]: Validation Loss: 3.1112\n",
      "Epoch [91/200]: Training Loss: 2.6693\n",
      "Epoch [91/200]: Validation Loss: 3.0251\n",
      "Epoch [92/200]: Training Loss: 2.6980\n",
      "Epoch [92/200]: Validation Loss: 2.9752\n",
      "Epoch [93/200]: Training Loss: 2.7737\n",
      "Epoch [93/200]: Validation Loss: 2.9622\n",
      "Epoch [94/200]: Training Loss: 2.7750\n",
      "Epoch [94/200]: Validation Loss: 2.9470\n",
      "Epoch [95/200]: Training Loss: 2.6753\n",
      "Epoch [95/200]: Validation Loss: 2.9451\n",
      "Epoch [96/200]: Training Loss: 2.6672\n",
      "Epoch [96/200]: Validation Loss: 3.0324\n",
      "Epoch [97/200]: Training Loss: 2.7111\n",
      "Epoch [97/200]: Validation Loss: 3.0784\n",
      "Epoch [98/200]: Training Loss: 2.6651\n",
      "Epoch [98/200]: Validation Loss: 3.2165\n",
      "Epoch [99/200]: Training Loss: 2.7535\n",
      "Epoch [99/200]: Validation Loss: 3.1047\n",
      "Epoch [100/200]: Training Loss: 2.6398\n",
      "Epoch [100/200]: Validation Loss: 3.0960\n",
      "Epoch [101/200]: Training Loss: 2.7150\n",
      "Epoch [101/200]: Validation Loss: 3.0083\n",
      "Epoch [102/200]: Training Loss: 2.7922\n",
      "Epoch [102/200]: Validation Loss: 3.0125\n",
      "Epoch [103/200]: Training Loss: 2.7439\n",
      "Epoch [103/200]: Validation Loss: 2.9570\n",
      "Epoch [104/200]: Training Loss: 2.6823\n",
      "Epoch [104/200]: Validation Loss: 2.9754\n",
      "Epoch [105/200]: Training Loss: 2.6973\n",
      "Epoch [105/200]: Validation Loss: 3.1030\n",
      "Epoch [106/200]: Training Loss: 2.5777\n",
      "Epoch [106/200]: Validation Loss: 3.1621\n",
      "Epoch [107/200]: Training Loss: 2.6249\n",
      "Epoch [107/200]: Validation Loss: 3.1920\n",
      "Epoch [108/200]: Training Loss: 2.6612\n",
      "Epoch [108/200]: Validation Loss: 3.1692\n",
      "Epoch [109/200]: Training Loss: 2.6241\n",
      "Epoch [109/200]: Validation Loss: 3.1584\n",
      "Epoch [110/200]: Training Loss: 2.6844\n",
      "Epoch [110/200]: Validation Loss: 2.9588\n",
      "Epoch [111/200]: Training Loss: 2.6837\n",
      "Epoch [111/200]: Validation Loss: 2.8962\n",
      "Epoch [112/200]: Training Loss: 2.7188\n",
      "Epoch [112/200]: Validation Loss: 3.0373\n",
      "Epoch [113/200]: Training Loss: 2.7391\n",
      "Epoch [113/200]: Validation Loss: 2.8532\n",
      "Epoch [114/200]: Training Loss: 2.6501\n",
      "Epoch [114/200]: Validation Loss: 2.8690\n",
      "Epoch [115/200]: Training Loss: 2.6733\n",
      "Epoch [115/200]: Validation Loss: 2.9987\n",
      "Epoch [116/200]: Training Loss: 2.7054\n",
      "Epoch [116/200]: Validation Loss: 2.9846\n",
      "Epoch [117/200]: Training Loss: 2.6237\n",
      "Epoch [117/200]: Validation Loss: 3.1340\n",
      "Epoch [118/200]: Training Loss: 2.6342\n",
      "Epoch [118/200]: Validation Loss: 3.0906\n",
      "Epoch [119/200]: Training Loss: 2.6334\n",
      "Epoch [119/200]: Validation Loss: 3.1163\n",
      "Epoch [120/200]: Training Loss: 2.7750\n",
      "Epoch [120/200]: Validation Loss: 3.0894\n",
      "Epoch [121/200]: Training Loss: 2.6883\n",
      "Epoch [121/200]: Validation Loss: 3.0713\n",
      "Epoch [122/200]: Training Loss: 2.6431\n",
      "Epoch [122/200]: Validation Loss: 2.8603\n",
      "Epoch [123/200]: Training Loss: 2.6661\n",
      "Epoch [123/200]: Validation Loss: 2.8123\n",
      "Epoch [124/200]: Training Loss: 2.7415\n",
      "Epoch [124/200]: Validation Loss: 2.6268\n",
      "Epoch [125/200]: Training Loss: 2.4945\n",
      "Epoch [125/200]: Validation Loss: 2.9162\n",
      "Epoch [126/200]: Training Loss: 2.7223\n",
      "Epoch [126/200]: Validation Loss: 2.9297\n",
      "Epoch [127/200]: Training Loss: 2.6773\n",
      "Epoch [127/200]: Validation Loss: 2.8577\n",
      "Epoch [128/200]: Training Loss: 2.6144\n",
      "Epoch [128/200]: Validation Loss: 2.9286\n",
      "Epoch [129/200]: Training Loss: 2.6039\n",
      "Epoch [129/200]: Validation Loss: 2.9427\n",
      "Epoch [130/200]: Training Loss: 2.6081\n",
      "Epoch [130/200]: Validation Loss: 3.0395\n",
      "Epoch [131/200]: Training Loss: 2.6820\n",
      "Epoch [131/200]: Validation Loss: 3.0212\n",
      "Epoch [132/200]: Training Loss: 2.5620\n",
      "Epoch [132/200]: Validation Loss: 3.0890\n",
      "Epoch [133/200]: Training Loss: 2.5601\n",
      "Epoch [133/200]: Validation Loss: 3.0719\n",
      "Epoch [134/200]: Training Loss: 2.6323\n",
      "Epoch [134/200]: Validation Loss: 2.9602\n",
      "Epoch [135/200]: Training Loss: 2.5863\n",
      "Epoch [135/200]: Validation Loss: 2.9836\n",
      "Epoch [136/200]: Training Loss: 2.5569\n",
      "Epoch [136/200]: Validation Loss: 2.8999\n",
      "Epoch [137/200]: Training Loss: 2.5188\n",
      "Epoch [137/200]: Validation Loss: 2.8914\n",
      "Epoch [138/200]: Training Loss: 2.5148\n",
      "Epoch [138/200]: Validation Loss: 2.8539\n",
      "Epoch [139/200]: Training Loss: 2.5759\n",
      "Epoch [139/200]: Validation Loss: 2.9268\n",
      "Epoch [140/200]: Training Loss: 2.5151\n",
      "Epoch [140/200]: Validation Loss: 2.9873\n",
      "Epoch [141/200]: Training Loss: 2.5702\n",
      "Epoch [141/200]: Validation Loss: 2.9750\n",
      "Epoch [142/200]: Training Loss: 2.5573\n",
      "Epoch [142/200]: Validation Loss: 3.0359\n",
      "Epoch [143/200]: Training Loss: 2.4647\n",
      "Epoch [143/200]: Validation Loss: 2.9962\n",
      "Epoch [144/200]: Training Loss: 2.5820\n",
      "Epoch [144/200]: Validation Loss: 3.0948\n",
      "Epoch [145/200]: Training Loss: 2.5868\n",
      "Epoch [145/200]: Validation Loss: 2.9968\n",
      "Epoch [146/200]: Training Loss: 2.6307\n",
      "Epoch [146/200]: Validation Loss: 2.8941\n",
      "Epoch [147/200]: Training Loss: 2.5166\n",
      "Epoch [147/200]: Validation Loss: 2.8622\n",
      "Epoch [148/200]: Training Loss: 2.4071\n",
      "Epoch [148/200]: Validation Loss: 2.8807\n",
      "Epoch [149/200]: Training Loss: 2.4390\n",
      "Epoch [149/200]: Validation Loss: 2.9157\n",
      "Epoch [150/200]: Training Loss: 2.4690\n",
      "Epoch [150/200]: Validation Loss: 2.8950\n",
      "Epoch [151/200]: Training Loss: 2.5907\n",
      "Epoch [151/200]: Validation Loss: 2.8762\n",
      "Epoch [152/200]: Training Loss: 2.5502\n",
      "Epoch [152/200]: Validation Loss: 2.8825\n",
      "Epoch [153/200]: Training Loss: 2.5834\n",
      "Epoch [153/200]: Validation Loss: 2.8059\n",
      "Epoch [154/200]: Training Loss: 2.4827\n",
      "Epoch [154/200]: Validation Loss: 2.9663\n",
      "Epoch [155/200]: Training Loss: 2.4112\n",
      "Epoch [155/200]: Validation Loss: 2.9912\n",
      "Epoch [156/200]: Training Loss: 2.4997\n",
      "Epoch [156/200]: Validation Loss: 3.0131\n",
      "Epoch [157/200]: Training Loss: 2.4699\n",
      "Epoch [157/200]: Validation Loss: 2.9448\n",
      "Epoch [158/200]: Training Loss: 2.3896\n",
      "Epoch [158/200]: Validation Loss: 2.8408\n",
      "Epoch [159/200]: Training Loss: 2.5926\n",
      "Epoch [159/200]: Validation Loss: 2.8823\n",
      "Epoch [160/200]: Training Loss: 2.3669\n",
      "Epoch [160/200]: Validation Loss: 2.9566\n",
      "Epoch [161/200]: Training Loss: 2.5309\n",
      "Epoch [161/200]: Validation Loss: 3.0416\n",
      "Epoch [162/200]: Training Loss: 2.3808\n",
      "Epoch [162/200]: Validation Loss: 2.9886\n",
      "Epoch [163/200]: Training Loss: 2.6218\n",
      "Epoch [163/200]: Validation Loss: 2.9309\n",
      "Epoch [164/200]: Training Loss: 2.5094\n",
      "Epoch [164/200]: Validation Loss: 2.7684\n",
      "Epoch [165/200]: Training Loss: 2.5449\n",
      "Epoch [165/200]: Validation Loss: 2.6615\n",
      "Epoch [166/200]: Training Loss: 2.4745\n",
      "Epoch [166/200]: Validation Loss: 2.6909\n",
      "Epoch [167/200]: Training Loss: 2.5997\n",
      "Epoch [167/200]: Validation Loss: 2.7734\n",
      "Epoch [168/200]: Training Loss: 2.4467\n",
      "Epoch [168/200]: Validation Loss: 2.7157\n",
      "Epoch [169/200]: Training Loss: 2.4566\n",
      "Epoch [169/200]: Validation Loss: 2.8320\n",
      "Epoch [170/200]: Training Loss: 2.4593\n",
      "Epoch [170/200]: Validation Loss: 2.8038\n",
      "Epoch [171/200]: Training Loss: 2.5796\n",
      "Epoch [171/200]: Validation Loss: 2.9212\n",
      "Epoch [172/200]: Training Loss: 2.3601\n",
      "Epoch [172/200]: Validation Loss: 2.9803\n",
      "Epoch [173/200]: Training Loss: 2.4142\n",
      "Epoch [173/200]: Validation Loss: 2.9230\n",
      "Epoch [174/200]: Training Loss: 2.4104\n",
      "Epoch [174/200]: Validation Loss: 2.9185\n",
      "Epoch [175/200]: Training Loss: 2.4018\n",
      "Epoch [175/200]: Validation Loss: 2.8545\n",
      "Epoch [176/200]: Training Loss: 2.5015\n",
      "Epoch [176/200]: Validation Loss: 2.9573\n",
      "Epoch [177/200]: Training Loss: 2.6173\n",
      "Epoch [177/200]: Validation Loss: 2.8097\n",
      "Epoch [178/200]: Training Loss: 2.4654\n",
      "Epoch [178/200]: Validation Loss: 2.6726\n",
      "Epoch [179/200]: Training Loss: 2.4966\n",
      "Epoch [179/200]: Validation Loss: 2.6275\n",
      "Epoch [180/200]: Training Loss: 2.5242\n",
      "Epoch [180/200]: Validation Loss: 2.7966\n",
      "Epoch [181/200]: Training Loss: 2.6200\n",
      "Epoch [181/200]: Validation Loss: 2.5030\n",
      "Epoch [182/200]: Training Loss: 2.4906\n",
      "Epoch [182/200]: Validation Loss: 2.5538\n",
      "Epoch [183/200]: Training Loss: 2.4898\n",
      "Epoch [183/200]: Validation Loss: 2.8128\n",
      "Epoch [184/200]: Training Loss: 2.4213\n",
      "Epoch [184/200]: Validation Loss: 2.7298\n",
      "Epoch [185/200]: Training Loss: 2.4573\n",
      "Epoch [185/200]: Validation Loss: 2.8674\n",
      "Epoch [186/200]: Training Loss: 2.3549\n",
      "Epoch [186/200]: Validation Loss: 3.0547\n",
      "Epoch [187/200]: Training Loss: 2.3320\n",
      "Epoch [187/200]: Validation Loss: 2.9678\n",
      "Epoch [188/200]: Training Loss: 2.4401\n",
      "Epoch [188/200]: Validation Loss: 2.9690\n",
      "Epoch [189/200]: Training Loss: 2.6230\n",
      "Epoch [189/200]: Validation Loss: 2.8721\n",
      "Epoch [190/200]: Training Loss: 2.3679\n",
      "Epoch [190/200]: Validation Loss: 2.7794\n",
      "Epoch [191/200]: Training Loss: 2.4122\n",
      "Epoch [191/200]: Validation Loss: 2.6764\n",
      "Epoch [192/200]: Training Loss: 2.4915\n",
      "Epoch [192/200]: Validation Loss: 2.6718\n",
      "Epoch [193/200]: Training Loss: 2.4200\n",
      "Epoch [193/200]: Validation Loss: 2.8056\n",
      "Epoch [194/200]: Training Loss: 2.5704\n",
      "Epoch [194/200]: Validation Loss: 2.8496\n",
      "Epoch [195/200]: Training Loss: 2.4234\n",
      "Epoch [195/200]: Validation Loss: 2.8662\n",
      "Epoch [196/200]: Training Loss: 2.4065\n",
      "Epoch [196/200]: Validation Loss: 2.8075\n",
      "Epoch [197/200]: Training Loss: 2.4344\n",
      "Epoch [197/200]: Validation Loss: 2.6347\n",
      "Epoch [198/200]: Training Loss: 2.4780\n",
      "Epoch [198/200]: Validation Loss: 2.9703\n",
      "Epoch [199/200]: Training Loss: 2.4633\n",
      "Epoch [199/200]: Validation Loss: 2.8524\n",
      "Epoch [200/200]: Training Loss: 2.4840\n",
      "Epoch [200/200]: Validation Loss: 2.7667\n"
     ]
    }
   ],
   "source": [
    "# Training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss = train(model,epoch,train_source_data,train_target_data, criterion, optimizer, device)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}]: Training Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    val_loss = evaluate(model,epoch,val_source_data,val_target_data, criterion,device)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}]: Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), 'data2vis_model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {index: char for char, index in char_to_index.items()}\n",
    "\n",
    "class BeamSearchNode:\n",
    "    def __init__(self, decoder_input, hidden, cell, log_prob, length):\n",
    "        self.decoder_input = decoder_input\n",
    "        self.hidden = hidden\n",
    "        self.cell = cell\n",
    "        self.log_prob = log_prob\n",
    "        self.length = length\n",
    "\n",
    "def beam_search_decode(model, src, max_length, beam_width):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the source sequence\n",
    "        encoder_outputs, (hidden, cell) = model.encoder(src)\n",
    "        start_symbol = torch.tensor([[char_to_index['#']]], device=device)\n",
    "        beam_search_nodes = [BeamSearchNode(start_symbol, hidden, cell, 0, 0)]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            new_nodes = []\n",
    "\n",
    "            for node in beam_search_nodes:\n",
    "                decoder_input = node.decoder_input.view(-1)\n",
    "                hidden = node.hidden.squeeze().unsqueeze(1)\n",
    "                cell = node.cell.squeeze().unsqueeze(1)\n",
    "                encoder_outputs=encoder_outputs.squeeze().unsqueeze(1)\n",
    "                log_prob = node.log_prob\n",
    "                length = node.length\n",
    "                # Decoding step\n",
    "                output, hidden, cell = model.decoder(decoder_input, hidden, cell, encoder_outputs)\n",
    "\n",
    "                # Get the top-k predictions and their probabilities\n",
    "                log_probs, indices = torch.topk(nn.functional.log_softmax(output, dim=1), beam_width)\n",
    "\n",
    "                for i in range(beam_width):\n",
    "                    new_decoder_input = indices[0][i].unsqueeze(0).unsqueeze(0)\n",
    "                    new_log_prob = log_probs[0][i].item()\n",
    "\n",
    "                    # If the next token is the padding token, stop generating\n",
    "                    if new_decoder_input.item() == char_to_index['^']:\n",
    "                        new_length = length\n",
    "                    else:\n",
    "                        new_length = length + 1\n",
    "                        \n",
    "                    new_nodes.append(\n",
    "                        BeamSearchNode(new_decoder_input, hidden, cell, log_prob + new_log_prob, new_length)\n",
    "                    )\n",
    "\n",
    "            new_nodes.sort(key=lambda x: x.log_prob, reverse=True)\n",
    "            beam_search_nodes = new_nodes[:beam_width]\n",
    "            \n",
    "        best_node = beam_search_nodes[0]\n",
    "\n",
    "        # Generate the decoded sequence\n",
    "        decoded_sequence = [best_node.decoder_input.item()]\n",
    "        for _ in range(best_node.length - 1):\n",
    "            output, best_node.hidden, best_node.cell = model.decoder(\n",
    "                best_node.decoder_input.view(-1), best_node.hidden, best_node.cell,encoder_outputs\n",
    "            )\n",
    "            best_decoder_input = output.argmax(dim=1)\n",
    "            decoded_sequence.append(best_decoder_input.item())\n",
    "            best_node.decoder_input = best_decoder_input\n",
    "\n",
    "        return decoded_sequence\n",
    "\n",
    "\n",
    "model = Seq2Seq(Encoder(len(char_vocab), embedding_dim, hidden_dim, 2, dropout_prob),\n",
    "                Decoder(len(char_vocab), embedding_dim, hidden_dim, 2, dropout_prob, Attention(hidden_dim)),\n",
    "                device)\n",
    "model_state_dict = torch.load('data2vis_model1.pth')\n",
    "model_state_dict = {k: v for k, v in model_state_dict.items() if k in model.state_dict()}\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Perform inference using beam search\n",
    "test_idx = 0\n",
    "src_sequence = test_source_data[test_idx].to(device)\n",
    "decoded_sequence = beam_search_decode(model, src_sequence, max_length=2000, beam_width=15)\n",
    "\n",
    "# Convert the decoded sequence back to characters\n",
    "decoded_sequence_chars = [index_to_char[idx] for idx in decoded_sequence]\n",
    "\n",
    "# print(\"Decoded Sequence:\", decoded_sequence_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perplexity(model, source_data, target_data, criterion, device):\n",
    "    model.eval()\n",
    "    total_log_perplexity = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step in range(len(source_data) // 256):\n",
    "            start_idx = step * batch_size\n",
    "            end_idx = (step + 1) * batch_size\n",
    "            source_batch = source_data[start_idx:end_idx].to(device)\n",
    "            target_batch = target_data[start_idx:end_idx].to(device)\n",
    "\n",
    "            source_batch, target_batch = source_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            output = model(source_batch, target_batch, teacher_forcing_ratio=0.0)\n",
    "            output_dim = output.shape[2]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            target_batch = target_batch[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, target_batch)\n",
    "            total_log_perplexity += loss.item()\n",
    "            total_tokens += target_batch.numel()\n",
    "\n",
    "    average_log_perplexity = total_log_perplexity / total_tokens\n",
    "    return average_log_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_perplexity = evaluate_perplexity(model, test_source_data, test_target_data, criterion, device)\n",
    "print(f'Test Average Log Perplexity: {test_log_perplexity:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
